{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1342d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score, precision_recall_curve,auc\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4caa46f",
   "metadata": {},
   "source": [
    "## 1. Data preprocessing\n",
    "\n",
    "- The merged dataset containers data leakage features which are features that wouldnt be available in real-world prediction such as `max_delay`, `avg_delay`, `num_bad_months`, `months_total`. The target variable `label`, `id` and `amt_income_total` (to use the log transformed income) are also dropped. The target variable `label` is converted to integer for classification\n",
    "- Applied one-hot encoding to categorical variables \n",
    "- Applied train-test split and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae02ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/clean_merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071e033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].astype('int')\n",
    "leaky_features = ['max_delay', 'avg_delay', 'num_bad_months', 'months_total']\n",
    "X = df.drop(columns=['label', 'id', 'amt_income_total'] + leaky_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a0cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True) #one-hot encoding\n",
    "else:\n",
    "    X_encoded = X\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e520f99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_gender</th>\n",
       "      <th>flag_own_car</th>\n",
       "      <th>flag_own_realty</th>\n",
       "      <th>cnt_children</th>\n",
       "      <th>flag_mobil</th>\n",
       "      <th>flag_work_phone</th>\n",
       "      <th>flag_phone</th>\n",
       "      <th>flag_email</th>\n",
       "      <th>cnt_fam_members</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>occupation_type_Low-skill Laborers</th>\n",
       "      <th>occupation_type_Managers</th>\n",
       "      <th>occupation_type_Medicine staff</th>\n",
       "      <th>occupation_type_Private service staff</th>\n",
       "      <th>occupation_type_Realty agents</th>\n",
       "      <th>occupation_type_Sales staff</th>\n",
       "      <th>occupation_type_Secretaries</th>\n",
       "      <th>occupation_type_Security staff</th>\n",
       "      <th>occupation_type_Unknown</th>\n",
       "      <th>occupation_type_Waiters/barmen staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24270</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29783</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18805</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       code_gender  flag_own_car  flag_own_realty  cnt_children  flag_mobil  \\\n",
       "8361             1             0                1             2           1   \n",
       "24270            0             1                0             2           1   \n",
       "14938            1             1                1             1           1   \n",
       "29783            1             1                1             1           1   \n",
       "18805            0             1                1             0           1   \n",
       "\n",
       "       flag_work_phone  flag_phone  flag_email  cnt_fam_members  age  ...  \\\n",
       "8361                 0           0           0                4   44  ...   \n",
       "24270                1           1           0                4   26  ...   \n",
       "14938                0           0           0                3   29  ...   \n",
       "29783                0           0           0                3   51  ...   \n",
       "18805                0           0           1                2   42  ...   \n",
       "\n",
       "       occupation_type_Low-skill Laborers  occupation_type_Managers  \\\n",
       "8361                                False                     False   \n",
       "24270                               False                     False   \n",
       "14938                               False                     False   \n",
       "29783                               False                      True   \n",
       "18805                               False                     False   \n",
       "\n",
       "       occupation_type_Medicine staff  occupation_type_Private service staff  \\\n",
       "8361                            False                                  False   \n",
       "24270                           False                                  False   \n",
       "14938                           False                                  False   \n",
       "29783                           False                                  False   \n",
       "18805                           False                                  False   \n",
       "\n",
       "       occupation_type_Realty agents  occupation_type_Sales staff  \\\n",
       "8361                           False                        False   \n",
       "24270                          False                        False   \n",
       "14938                          False                        False   \n",
       "29783                          False                        False   \n",
       "18805                          False                        False   \n",
       "\n",
       "       occupation_type_Secretaries  occupation_type_Security staff  \\\n",
       "8361                         False                           False   \n",
       "24270                        False                           False   \n",
       "14938                        False                           False   \n",
       "29783                        False                           False   \n",
       "18805                        False                           False   \n",
       "\n",
       "       occupation_type_Unknown  occupation_type_Waiters/barmen staff  \n",
       "8361                      True                                 False  \n",
       "24270                    False                                 False  \n",
       "14938                    False                                 False  \n",
       "29783                    False                                 False  \n",
       "18805                     True                                 False  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7beaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48e5805c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of y after SMOTE: Counter({0: 23531, 1: 23531})\n",
      "Class distribution of y without SMOTE: Counter({0: 5884, 1: 116})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# apply SMOTE \n",
    "smote = SMOTE(random_state=42)\n",
    "X_balance, y_balance = smote.fit_resample(X_train, y_train)\n",
    "print(f\"Class distribution of y after SMOTE: {Counter(y_balance)}\")\n",
    "print(f\"Class distribution of y without SMOTE: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9148db7",
   "metadata": {},
   "source": [
    "## 2. Random Forest Model (Baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45dcbdd",
   "metadata": {},
   "source": [
    "### 2.1 Baseline model\n",
    "\n",
    "Random Forest is an ensemble learning method based on building multiple decision trees during training and combining their predictions by majority vote for classification. \n",
    "\n",
    "This makes the model:\n",
    "- Generalise better and avoid overfitting\n",
    "- Handle non-linear relationships\n",
    "- Automatically estimate feature importance\n",
    "\n",
    "The first model is a baseline model that is simple and unoptimised version that uses the original imbalanced data with default Random Forest hyperparameters to provide a reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea00353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9786666666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5884\n",
      "           1       0.34      0.11      0.17       116\n",
      "\n",
      "    accuracy                           0.98      6000\n",
      "   macro avg       0.66      0.55      0.58      6000\n",
      "weighted avg       0.97      0.98      0.97      6000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5859   25]\n",
      " [ 103   13]]\n",
      "\n",
      "Rates:\n",
      "\n",
      "Specificity (True Negative Rate): 0.9958\n",
      "False Positive Rate: 0.0042\n",
      "Sensitivity (Recall/True Positive Rate): 0.1121\n",
      "False Negative Rate: 0.8879\n"
     ]
    }
   ],
   "source": [
    "# Train Random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # y_test loaded as true test targets\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "print(f\"\\nRates:\")\n",
    "\n",
    "total_0 = cm[0,0] + cm[0,1]  \n",
    "total_1 = cm[1,0] + cm[1,1] \n",
    "\n",
    "print(f\"\\nSpecificity (True Negative Rate): {cm[0,0]/total_0:.4f}\")\n",
    "print(f\"False Positive Rate: {cm[0,1]/total_0:.4f}\")\n",
    "print(f\"Sensitivity (Recall/True Positive Rate): {cm[1,1]/total_1:.4f}\")\n",
    "print(f\"False Negative Rate: {cm[1,0]/total_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767534e2",
   "metadata": {},
   "source": [
    "### 2.2 Baseline Model (using only the top 10 most important features)\n",
    "\n",
    "Rationale for reducing to top 10 most important features:\n",
    "- Interpretability \n",
    "- Eliminates noisy or irrelevant features that might affect accuracy of model\n",
    "- Reduce likelihood of model learning random patterns \n",
    "- Fewer inputs = Increase training efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ec2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances and feature names\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Make a DataFrame for easy sorting/viewing\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top N features (e.g. top 15)\n",
    "N = 15\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feat_imp_df['feature'][:N][::-1], feat_imp_df['importance'][:N][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top Feature Importances from Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231c5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_imp_df.head(10))  # Show top 10 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce train and test to selected features\n",
    "\n",
    "N = 10\n",
    "top_features = feat_imp_df['feature'].iloc[:N].tolist()\n",
    "top_features\n",
    "\n",
    "X_train_reduced = X_train[top_features]\n",
    "X_test_reduced = X_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reduced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "y_pred_reduced = rf_reduced.predict(X_test_reduced)\n",
    "\n",
    "print(\"Accuracy with reduced features:\", accuracy_score(y_test, y_pred_reduced))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_reduced))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64787df",
   "metadata": {},
   "source": [
    "After feature reduction:\n",
    "- Accuracy improved slightly: 0.9809380142622052 to 0.9810751508502469 \n",
    "- Recall for target label 0 (no approval) is still 1.00\n",
    "- Recall for target label 1 (approval) improved slightly: 0.15 to 0.16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_reduced = rf_reduced.predict_proba(X_test_reduced)[:, 1]  # Probability of class '1'\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba_reduced)  # y_test = true labels\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_proba_reduced)\n",
    "print(f\"AUC: {auc_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ea64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC Curve\n",
    "plt.figure(figsize = (6, 5))\n",
    "plt.plot(fpr, tpr, label = f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label = 'Random Guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Random Forest')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec70765",
   "metadata": {},
   "source": [
    "### 2.3 GridSearchCV to find the best combination of hyperparameters for Random Forest Model \n",
    "\n",
    "Rationale for GridSearchCV:\n",
    "- We want to improve model performance (measured by ROC-AUC) by testing different parameter settings (n_estimators, max_depth, min_samples_split) systematically.\n",
    "\n",
    "Key Random Forest hyperparameters:\n",
    "- `n_estimators`: Number of trees in the Random Forest. Having more trees can improve model performance but increase training time. \n",
    "- `max_depth`: Maximum depth of each tree which controls the model complexity\n",
    "- `min_samples_split`: Minimum samples required to split a node. Larger `min_samples_split` prevents overfitting as it requires more samples to create a split.\n",
    "\n",
    "#### How the GridSearchCV works?\n",
    "\n",
    "GridSearchCV tries every combination in the grid, using cross-validation (CV) to evaluate each combination. We chose cv = 3 (3-fold CV splits), splits the data into 3 parts. The model is trained 3 rounds, each round, the model is trained on a different 2/3 of the data. This CV ensures the model generalises well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state = 42),\n",
    "    param_grid,\n",
    "    cv = 3,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 1,       # <<< Only use 1 job (no parallel, less stress on env)\n",
    "    verbose = 2\n",
    ")\n",
    "grid_rf.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccdabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Random Forest params:\", grid_rf.best_params_)\n",
    "print(\"Best cross-validated AUC:\", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb7a7e",
   "metadata": {},
   "source": [
    "The performance of the optimal hyperparameter combination identified by GridSearchCV was evaluated using the ROC-AUC metric.\n",
    "\n",
    "ROC-AUC measures how well the Random Forest model separates the 2 classes (defaulters vs. non-defaulters)\n",
    "\n",
    "Rationale for using ROC-AUC:\n",
    "- We have identified the dataset to be imbalanced, so using accuracy metric can be misleading. A model that always predicts the majority class could still appear \"accurate\", even though it performs poorly on the minority class. Thus, the model might fail to identify important minority cases, like defaulters, which could cause harm to the bank.\n",
    "- In contrast, ROC-AUC looks at how well the model separates defaulters vs. non-defaulters, so it is much more reliable compared to accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b012b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Best Model on Test Set\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# Predict probabilities (for AUC) and classes\n",
    "y_proba = grid_rf.best_estimator_.predict_proba(X_test_reduced)[:, 1]\n",
    "y_pred = grid_rf.best_estimator_.predict(X_test_reduced)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Test set ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e213f71a",
   "metadata": {},
   "source": [
    "Based on the Classification Report, even though the ROC-AUC shows a high value of 0.80, the recall value is low, and false negative rate is very high (0.88). In the financial institution context, type II error which is the false negative rate might be a greater consequence. The model would approve a credit card for someone who is actually a bad customer (likely to default) the bank loses money if the applicant with a poor credit history gets approved, and later fails to pay. Hence, to improve on this, section 3 contains different enhancements made to the baseline model to improve the performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b946a1",
   "metadata": {},
   "source": [
    "## 3. Random Forest Model Enhancements / Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46f467",
   "metadata": {},
   "source": [
    "### 3.1 Random Forest Model with SMOTE and Fixed Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a7beb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8898\n",
      "ROC AUC: 0.6425\n",
      "PR AUC: 0.0448\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      5884\n",
      "           1       0.05      0.27      0.09       116\n",
      "\n",
      "    accuracy                           0.89      6000\n",
      "   macro avg       0.52      0.58      0.51      6000\n",
      "weighted avg       0.97      0.89      0.92      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5308  576]\n",
      " [  85   31]]\n",
      "\n",
      "Rates:\n",
      "Specificity (True Negative Rate): 0.9021\n",
      "False Positive Rate: 0.0979\n",
      "Sensitivity (Recall/True Positive Rate): 0.2672\n",
      "False Negative Rate: 0.7328\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rf_model_smote = RandomForestClassifier(\n",
    "    n_estimators = 100,        # no. of trees\n",
    "    max_depth = 10,           \n",
    "    min_samples_split = 20,   \n",
    "    min_samples_leaf = 10,\n",
    "    max_features = 'sqrt',     # random feature selection, diff trees see different subset of features \n",
    "    bootstrap = True,          # bagging, ensemble learning\n",
    "    random_state = 42,\n",
    "    n_jobs = -1               # for parallel processing\n",
    ")\n",
    "\n",
    "rf_model_smote.fit(X_balance, y_balance)\n",
    "\n",
    "#  predictions\n",
    "y_pred_smote = rf_model_smote.predict(X_test)\n",
    "y_pred_proba_smote = rf_model_smote.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# performance metrics \n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_proba_smote)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_smote):.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "\n",
    "# confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_smote)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nRates:\")\n",
    "total_0 = cm[0,0] + cm[0,1]  \n",
    "total_1 = cm[1,0] + cm[1,1] \n",
    "\n",
    "\n",
    "print(f\"Specificity (True Negative Rate): {cm[0,0]/total_0:.4f}\")\n",
    "print(f\"False Positive Rate: {cm[0,1]/total_0:.4f}\")\n",
    "print(f\"Sensitivity (Recall/True Positive Rate): {cm[1,1]/total_1:.4f}\")\n",
    "print(f\"False Negative Rate: {cm[1,0]/total_1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve \n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_smote)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_pred_proba_smote):.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Random Forest')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f22b0c",
   "metadata": {},
   "source": [
    "Issues with random forest model using training set balanced using smote:\n",
    "\n",
    "1. AUC of 0.6 is only slightly better than random guesssing, contradicts the 0.90 accuracy rate. The accuracy rate might be misleading because majority class dominates (`label` = 0 for non default). The model might not be discriminating well between the 2 classes. \n",
    "\n",
    "2. Although recall increased from the baseline model (0.20 from 0.11), the trade off is lower precision and f1 score as these are nearly 0 for `label` = 1. Since the minority class is extremely small (about 0.02%), SMOTE might produce unrealisitc synthetic minority points, and the model might be overfitting to the SMOTE-generated data by learning the artificial patterns created by SMOTE but not generalizing well to the test set. Some features are dominated by 0s or categorical dummies.\n",
    "\n",
    "3. Potential changes made to this model: \n",
    " - to lower the threshold to 0.3 from 0.5 to capture more defaulters (true positives) (refer to section 3.2)\n",
    " - to change to class_weight=\"balanced\" to replace SMOTE (refer to section 3.4)\n",
    " - change the model with features that are engineered (refer to section 3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004b2ac4",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest Model (adjusted threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d1c37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5453\n",
      "ROC AUC: 0.6425\n",
      "PR AUC: 0.0448\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.54      0.70      5884\n",
      "           1       0.03      0.64      0.05       116\n",
      "\n",
      "    accuracy                           0.55      6000\n",
      "   macro avg       0.51      0.59      0.38      6000\n",
      "weighted avg       0.97      0.55      0.69      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3198 2686]\n",
      " [  42   74]]\n",
      "\n",
      "Rates:\n",
      "Specificity (True Negative Rate): 0.5435\n",
      "False Positive Rate: 0.4565\n",
      "Sensitivity (Recall/True Positive Rate): 0.6379\n",
      "False Negative Rate: 0.3621\n"
     ]
    }
   ],
   "source": [
    "rf_model_thres = RandomForestClassifier(\n",
    "    n_estimators=100,        # no. of trees\n",
    "    max_depth=10,           \n",
    "    min_samples_split=20,   \n",
    "    min_samples_leaf=10,\n",
    "    max_features='sqrt',     # random feature selection, diff trees see different subset of features \n",
    "    bootstrap=True,          # bagging, ensemble learning\n",
    "    random_state=42,\n",
    "    n_jobs=-1               # for parallel processing\n",
    ")\n",
    "\n",
    "rf_model_thres.fit(X_balance, y_balance)\n",
    "\n",
    "y_pred_thres = rf_model_thres.predict(X_test)\n",
    "y_pred_proba_thres = rf_model_thres.predict_proba(X_test)[:, 1]\n",
    "threshold = 0.3\n",
    "y_pred_adj = (y_pred_proba_thres >= threshold).astype(int)\n",
    "\n",
    "\n",
    "# performance metrics \n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_proba_thres)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_adj):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_thres):.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_adj))\n",
    "\n",
    "# confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_adj)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nRates:\")\n",
    "total_0 = cm[0,0] + cm[0,1]  \n",
    "total_1 = cm[1,0] + cm[1,1] \n",
    "\n",
    "print(f\"Specificity (True Negative Rate): {cm[0,0]/total_0:.4f}\")\n",
    "print(f\"False Positive Rate: {cm[0,1]/total_0:.4f}\")\n",
    "print(f\"Sensitivity (Recall/True Positive Rate): {cm[1,1]/total_1:.4f}\")\n",
    "print(f\"False Negative Rate: {cm[1,0]/total_1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c76746",
   "metadata": {},
   "source": [
    "Recall for `label` = 1 increase significantly (0.6) but at the cost of much lower precision, F1-score and accuracy. Most non-defaulters are now wrongly flagged as defaulters. Adjusting threshold does not quite solve the issue since the model cannot tell defaulters apart confidently. Even at threshold 0.3, only a small group of samples truly correspond to real defaulters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f625fead",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest Model with Class-Weight Balancing Instead of SMOTE) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a4187",
   "metadata": {},
   "source": [
    "To address the severe class imbalance in the dataset, we trained a Random Forest with class_weight='balanced'. This approach automatically assigns higher importance to the minority class (defaulters) during training, without generating synthetic samples as in SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c71df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation AUC: 0.6830 (+/- 0.0415)\n",
      "Accuracy: 0.9515\n",
      "ROC AUC: 0.7112\n",
      "PR AUC: 0.1466\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      5884\n",
      "           1       0.17      0.40      0.24       116\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.58      0.68      0.61      6000\n",
      "weighted avg       0.97      0.95      0.96      6000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5663  221]\n",
      " [  70   46]]\n",
      "\n",
      "Rates:\n",
      "Specificity (True Negative Rate): 0.9624\n",
      "False Positive Rate: 0.0376\n",
      "Sensitivity (Recall/True Positive Rate): 0.3966\n",
      "False Negative Rate: 0.6034\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_model_cw = RandomForestClassifier(\n",
    "    n_estimators = 200,\n",
    "    max_depth = 15,\n",
    "    min_samples_leaf = 5,\n",
    "    min_samples_split = 10,\n",
    "    max_features = 'sqrt',\n",
    "    class_weight = 'balanced',\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "rf_model_cw.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_cw = rf_model_cw.predict(X_test)\n",
    "y_pred_proba_cw = rf_model_cw.predict_proba(X_test)[:, 1] \n",
    "\n",
    "cv_scores_rf = cross_val_score(rf_model_cw, X_train, y_train, cv = 5, scoring = 'roc_auc')\n",
    "print(f\"Cross-Validation AUC: {cv_scores_rf.mean():.4f} (+/- {cv_scores_rf.std() * 2:.4f})\")\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_test, y_pred_proba_cw)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_cw):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_cw):.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "print(\"\\n Classification Report\")\n",
    "print(classification_report(y_test, y_pred_cw))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_cw)\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nRates:\")\n",
    "\n",
    "total_0 = cm[0,0] + cm[0,1]  \n",
    "total_1 = cm[1,0] + cm[1,1] \n",
    "\n",
    "print(f\"Specificity (True Negative Rate): {cm[0,0]/total_0:.4f}\")\n",
    "print(f\"False Positive Rate: {cm[0,1]/total_0:.4f}\")\n",
    "print(f\"Sensitivity (Recall/True Positive Rate): {cm[1,1]/total_1:.4f}\")\n",
    "print(f\"False Negative Rate: {cm[1,0]/total_1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision recall curve\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(recall, precision, color='b', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision–Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e9d352",
   "metadata": {},
   "source": [
    "Most of the performance metric values improved quite a bit from the model that uses smote especially recall, false negative rate, pr auc which are most important as having high false negative rate can be quite costly if a defaulter is wrongly predicted as non-defaulter. Even though PR AUC improved slightly, but the model may be doing slightly better than random guessing only because the features might not provide enough information to distinguish between defaulters and non-defaulters. The model still struggles to detect the minority class effectively. Feature engineering will be done under the section 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340805a1",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest Model  With Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db85865",
   "metadata": {},
   "source": [
    "####   3.4.1 Check feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1811e707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     feature  importance\n",
      "11            years_employed    0.160557\n",
      "9                        age    0.152307\n",
      "12            amt_income_log    0.138161\n",
      "8            cnt_fam_members    0.043751\n",
      "3               cnt_children    0.032079\n",
      "2            flag_own_realty    0.031902\n",
      "1               flag_own_car    0.029517\n",
      "6                 flag_phone    0.027710\n",
      "16  name_income_type_Working    0.024644\n",
      "0                code_gender    0.024104\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_encoded.columns,\n",
    "    'importance': rf_model_cw.feature_importances_\n",
    "}).sort_values('importance', ascending = False)\n",
    "\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "top_features = feature_importance.head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(top_features['feature'][::-1], top_features['importance'][::-1], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 10 Feature Importances (Class-Weighted RF)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10323cbe",
   "metadata": {},
   "source": [
    "Based on the feature importance for the top 10 features, only the top 3 features seem to have predictive power as all other features have importance of less than 0.01. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d464ebd",
   "metadata": {},
   "source": [
    "#### 3.4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f44dea72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 30 features for modeling\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def new_features(X):\n",
    "   \n",
    "    X_eng = X.copy()\n",
    "    \n",
    "    # use ratio\n",
    "    if 'years_employed' in X.columns and 'age' in X.columns:\n",
    "        X_eng['career_ratio'] = X['years_employed'] / (X['age'] + 1)\n",
    "        X_eng['employment_stability'] = X['years_employed'] / (X['age'] - 18 + 1)  # Years since adult\n",
    "    \n",
    "    if 'amt_income_log' in X.columns and 'cnt_fam_members' in X.columns:\n",
    "        X_eng['income_per_member'] = X['amt_income_log'] / (X['cnt_fam_members'] + 1)\n",
    "        X_eng['log_income_per_member'] = np.log1p(X_eng['income_per_member'])\n",
    "    \n",
    "    # interaction terms\n",
    "    if 'age' in X.columns and 'amt_income_log' in X.columns:\n",
    "        X_eng['age_income_interaction'] = X['age'] * X['amt_income_log']\n",
    "        X_eng['age_income_ratio'] = X['age'] / (X['amt_income_log'] + 1)\n",
    "    \n",
    "    # nonlinear transf\n",
    "    if 'age' in X.columns:\n",
    "        X_eng['age_squared'] = X['age'] ** 2\n",
    "        X_eng['age_cubed'] = X['age'] ** 3\n",
    "        X_eng['log_age'] = np.log1p(X['age'])\n",
    "    \n",
    "    if 'years_employed' in X.columns:\n",
    "        X_eng['employment_squared'] = X['years_employed'] ** 2\n",
    "        X_eng['log_employment'] = np.log1p(X['years_employed'] + 1)\n",
    "    \n",
    "\n",
    "    return X_eng\n",
    "\n",
    "# apply the feature engineering defined above\n",
    "X_engineered = new_features(X_encoded)\n",
    "\n",
    "# use one-hot encoding for cat variables\n",
    "categorical_eng_cols = X_engineered.select_dtypes(include=['object', 'category']).columns\n",
    "if len(categorical_eng_cols) > 0:\n",
    "    X_engineered = pd.get_dummies(X_engineered, columns=categorical_eng_cols, drop_first=True)\n",
    "\n",
    "X_train_eng, X_test_eng, y_train, y_test = train_test_split(\n",
    "    X_engineered, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#  feature selection using correlation with target\n",
    "correlations = X_train_eng.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "\n",
    "# select top correlated features\n",
    "selected_features = correlations[correlations > 0.01].index.tolist()\n",
    "if len(selected_features) < 20: \n",
    "    selected_features = correlations.head(30).index.tolist()\n",
    "\n",
    "print(f\"Selected {len(selected_features)} features for modeling\")\n",
    "\n",
    "X_train_selected = X_train_eng[selected_features]\n",
    "X_test_selected = X_test_eng[selected_features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cedeb9",
   "metadata": {},
   "source": [
    "#### 3.4.3 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "493c8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation AUC: 0.7104 (+/- 0.0474)\n"
     ]
    }
   ],
   "source": [
    "rf_engineered = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=22,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=10,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_engineered.fit(X_train_selected, y_train)\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(rf_engineered, X_train_selected, y_train, \n",
    "                           cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"Cross-Validation AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "y_pred_eng = rf_engineered.predict(X_test_selected)\n",
    "y_pred_proba_eng = rf_engineered.predict_proba(X_test_selected)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aceb3dd",
   "metadata": {},
   "source": [
    "#### 3.4.4 Evaluation of Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82c52022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Random Forest with Feature Engineering=== Evaluation\n",
      "ROC AUC: 0.7386\n",
      "Accuracy: 0.9447\n",
      "PR AUC:  0.1468\n",
      "\n",
      "Confusion Matrix\n",
      "[[5620  264]\n",
      " [  68   48]]\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      5884\n",
      "           1       0.15      0.41      0.22       116\n",
      "\n",
      "    accuracy                           0.94      6000\n",
      "   macro avg       0.57      0.68      0.60      6000\n",
      "weighted avg       0.97      0.94      0.96      6000\n",
      "\n",
      "\n",
      "Rates:\n",
      "Specificity (True Negative Rate): 0.9551\n",
      "False Positive Rate: 0.0449\n",
      "Sensitivity (Recall/True Positive Rate): 0.4138\n",
      "False Negative Rate: 0.5862\n",
      "\n",
      "===Random Forest (No Engineering)=== Evaluation\n",
      "ROC AUC: 0.7112\n",
      "Accuracy: 0.9515\n",
      "PR AUC:  0.1468\n",
      "\n",
      "Confusion Matrix\n",
      "[[5663  221]\n",
      " [  70   46]]\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      5884\n",
      "           1       0.17      0.40      0.24       116\n",
      "\n",
      "    accuracy                           0.95      6000\n",
      "   macro avg       0.58      0.68      0.61      6000\n",
      "weighted avg       0.97      0.95      0.96      6000\n",
      "\n",
      "\n",
      "Rates:\n",
      "Specificity (True Negative Rate): 0.9624\n",
      "False Positive Rate: 0.0376\n",
      "Sensitivity (Recall/True Positive Rate): 0.3966\n",
      "False Negative Rate: 0.6034\n"
     ]
    }
   ],
   "source": [
    "def evaluation(model_name, y_test, y_pred, y_pred_proba, feature_names, model):\n",
    "    print(f\"\\n{model_name} Evaluation\")\n",
    "\n",
    "\n",
    "    roc_auc_value = roc_auc_score(y_test, y_pred_proba)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    pr_precision, pr_recall, _ = precision_recall_curve(y_test, y_pred_proba_eng)\n",
    "    pr_auc_value = auc(pr_recall, pr_precision)\n",
    "\n",
    "\n",
    "    print(f\"ROC AUC: {roc_auc_value:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"PR AUC:  {pr_auc_value:.4f}\") \n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(f\"\\nConfusion Matrix\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "\n",
    "    print(\"\\n Classification Report\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "   \n",
    "    total_0 = cm[0,0] + cm[0,1]\n",
    "    total_1 = cm[1,0] + cm[1,1]\n",
    "\n",
    "    print(f\"\\nRates:\")\n",
    "\n",
    "    print(f\"Specificity (True Negative Rate): {cm[0,0]/total_0:.4f}\")\n",
    "    print(f\"False Positive Rate: {cm[0,1]/total_0:.4f}\")\n",
    "    print(f\"Sensitivity (Recall/True Positive Rate): {cm[1,1]/total_1:.4f}\")\n",
    "    print(f\"False Negative Rate: {cm[1,0]/total_1:.4f}\")\n",
    "\n",
    "    # for plotting in part 2.4.5\n",
    "    return {\n",
    "        'roc_auc': roc_auc_value,\n",
    "        'pr_auc': pr_auc_value,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "#1.  evaluate engineered model\n",
    "results_eng = evaluation(\n",
    "    \"===Random Forest with Feature Engineering===\", \n",
    "    y_test, y_pred_eng, y_pred_proba_eng, \n",
    "    selected_features, rf_engineered\n",
    ")\n",
    "\n",
    "\n",
    "# 2.  train \"baseline\" model (using class weight (rf_model_cw), no feature engineering)\n",
    "\n",
    "results_cw = evaluation(\n",
    "    \"===Random Forest (No Engineering)===\", \n",
    "    y_test, y_pred_cw, y_pred_proba_cw, \n",
    "    X_train.columns, rf_model_cw\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1c73a2",
   "metadata": {},
   "source": [
    "#### 3.4.5 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# auc roc curve comparison plot\n",
    "plt.subplot(2, 3, 1)\n",
    "fpr_eng, tpr_eng, _ = roc_curve(y_test, y_pred_proba_eng)\n",
    "fpr_base, tpr_base, _ = roc_curve(y_test, y_pred_proba_cw)\n",
    "\n",
    "plt.plot(fpr_eng, tpr_eng, label=f'RF (FE) (AUC = {results_eng[\"roc_auc\"]:.4f})', linewidth=2)\n",
    "plt.plot(fpr_base, tpr_base, label=f'RF (Baseline CW) (AUC = {results_cw[\"roc_auc\"]:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC ROC Curve Comparison')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# performance metrics comparison plot\n",
    "plt.subplot(2, 3, 2)\n",
    "metrics = ['ROC AUC', 'PR AUC', 'Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "base_values = [results_cw['roc_auc'], results_cw['pr_auc'],results_cw['accuracy'], results_cw['precision'], \n",
    "               results_cw['recall'], results_cw['f1']]\n",
    "eng_values = [results_eng['roc_auc'], results_cw['pr_auc'], results_eng['accuracy'], results_eng['precision'], \n",
    "              results_eng['recall'], results_eng['f1']]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, base_values, width, label='RF (Baseline CW)', alpha=0.7)\n",
    "plt.bar(x + width/2, eng_values, width, label='RF (FE)', alpha=0.7)\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Performance Comparison')\n",
    "plt.xticks(x, metrics, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# precision recall curve plot\n",
    "plt.subplot(2, 3, 3)\n",
    "precision_eng, recall_eng, _ = precision_recall_curve(y_test, y_pred_proba_eng)\n",
    "precision_base, recall_base, _ = precision_recall_curve(y_test, y_pred_proba_cw)\n",
    "\n",
    "plt.plot(recall_eng, precision_eng, label='RF (FE)', linewidth=2)\n",
    "plt.plot(recall_base, precision_base, label='RF (Baseline CW)', linewidth=2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#  feature importance plot (show new features)\n",
    "plt.subplot(2, 3, 4)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'importance': rf_engineered.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Top 15 Feature Importances\\n(Engineered Model)')\n",
    "plt.xlabel('Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51ded3d",
   "metadata": {},
   "source": [
    "## 3. XGBOOST Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c9d6a",
   "metadata": {},
   "source": [
    "#### 3.1 XGBoost Model (version 1)\n",
    "\n",
    "Rationale of XGBoost with `scale_pos_weight` & regularisation:\n",
    "- Class imbalance handling using `scale_pos_weight = (# negatives / # positives)` which penalises mistakes on minority class more (defaulters). This would improve recall on the minority (defaulters).\n",
    "- Regularisation using `reg_alpha = 0.1` and `reg_lambda = 0.1` to reduce overfitting \n",
    "\n",
    "We chose log loss as the evaluation metric, because it trains XGBoost to penalise the model for being confidently wrong (in this case wrongly predicting defaulters as non-defaulters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## XGBoost (with Scale Pos Weight) and with regularisation\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,   \n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_xgb = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(f\"Cross-Validation AUC: {cv_scores_xgb.mean():.4f} (+/- {cv_scores_xgb.std() * 2:.4f})\")\n",
    "\n",
    "\n",
    "    # Basic metrics\n",
    "auc = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "precision = precision_score(y_test, y_pred_xgb)\n",
    "recall = recall_score(y_test, y_pred_xgb)\n",
    "f1 = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n Classification Report\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# Rates\n",
    "total_0 = cm[0,0] + cm[0,1]\n",
    "total_1 = cm[1,0] + cm[1,1]\n",
    "print(\"\\nRates:\")\n",
    "print(f\"Specificity: {cm[0,0]/total_0:.4f}\")\n",
    "print(f\"False Positive Rate: {cm[0,1]/total_0:.4f}\")\n",
    "print(f\"Sensitivity (Recall): {cm[1,1]/total_1:.4f}\")\n",
    "print(f\"False Negative Rate: {cm[1,0]/total_1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3064f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "rf_metrics = {\n",
    "    'AUC': roc_auc_score(y_test, y_pred_proba_cw),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_cw),\n",
    "    'Precision': precision_score(y_test, y_pred_cw),\n",
    "    'Recall': recall_score(y_test, y_pred_cw),\n",
    "    'F1': f1_score(y_test, y_pred_cw)\n",
    "}\n",
    "\n",
    "xgb_metrics = {\n",
    "    'AUC': roc_auc_score(y_test, y_pred_proba_xgb),\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'Precision': precision_score(y_test, y_pred_xgb),\n",
    "    'Recall': recall_score(y_test, y_pred_xgb),\n",
    "    'F1': f1_score(y_test, y_pred_xgb)\n",
    "}\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1, 3, 1)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_cw)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_proba_xgb)\n",
    "\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'RF CW (AUC={rf_metrics[\"AUC\"]:.4f})')\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={xgb_metrics[\"AUC\"]:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Precision-Recall Curve\n",
    "plt.subplot(1, 3, 2)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_pred_proba_cw)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_test, y_pred_proba_xgb)\n",
    "\n",
    "plt.plot(recall_rf, precision_rf, label='RF CW')\n",
    "plt.plot(recall_xgb, precision_xgb, label='XGBoost')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Metrics Comparison\n",
    "plt.subplot(1, 3, 3)\n",
    "metrics = ['AUC', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "rf_values = [rf_metrics[m] for m in metrics]\n",
    "xgb_values = [xgb_metrics[m] for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, rf_values, width, label='RF CW', alpha=0.7)\n",
    "plt.bar(x + width/2, xgb_values, width, label='XGBoost', alpha=0.7)\n",
    "plt.xticks(x, metrics, rotation=45)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Metrics Comparison')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb6f11",
   "metadata": {},
   "source": [
    "#### 3.2 Exploratory Hyperparameter Trace to get optimal no. of trees, max_depth, min_samples_leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Stratified CV\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "n_list = [50, 100, 200, 400, 800]\n",
    "means, stds = [], []\n",
    "\n",
    "for n in n_list:\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=n,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',   # keep the same imbalance strategy you used elsewhere\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cv = cross_val_score(rf, X_train, y_train, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "    means.append(cv.mean())\n",
    "    stds.append(cv.std())\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.errorbar(n_list, means, yerr=stds, fmt='-o', capsize=4)\n",
    "plt.xlabel(\"Number of Trees (n_estimators)\")\n",
    "plt.ylabel(\"CV ROC-AUC (mean ± 1 SD)\")\n",
    "plt.title(\"Random Forest Tuning Trace: Trees vs ROC-AUC (Stratified 5-fold)\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---- heatmap over (max_depth, min_samples_leaf) ---- \n",
    "depth_grid = [None, 8, 12, 16, 24]\n",
    "leaf_grid  = [1, 2, 5, 10]\n",
    "\n",
    "records = []\n",
    "for d in depth_grid:\n",
    "    for leaf in leaf_grid:\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=200,       # fix a reasonable value from the trace above\n",
    "            max_depth=d,\n",
    "            min_samples_leaf=leaf,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        cv = cross_val_score(rf, X_train, y_train, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "        records.append({\n",
    "            \"max_depth\": (\"None\" if d is None else d),\n",
    "            \"min_samples_leaf\": leaf,\n",
    "            \"auc_mean\": cv.mean()\n",
    "        })\n",
    "\n",
    "df_grid = pd.DataFrame(records)\n",
    "pivot = df_grid.pivot(index=\"max_depth\", columns=\"min_samples_leaf\", values=\"auc_mean\")\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "im = plt.imshow(pivot.values, aspect='auto', origin='lower')\n",
    "plt.colorbar(im, label=\"CV ROC-AUC\")\n",
    "plt.xticks(ticks=np.arange(len(leaf_grid)), labels=leaf_grid)\n",
    "plt.yticks(ticks=np.arange(len(depth_grid)), labels=[(\"None\" if d is None else d) for d in depth_grid])\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"max_depth\")\n",
    "plt.title(\"Random Forest Grid Trace: (depth, leaf) → ROC-AUC\")\n",
    "# annotate cells\n",
    "for i in range(pivot.shape[0]):\n",
    "    for j in range(pivot.shape[1]):\n",
    "        plt.text(j, i, f\"{pivot.values[i,j]:.3f}\", ha='center', va='center', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1622238",
   "metadata": {},
   "source": [
    "#### 3.3 Tuned XGBoost with new optimised parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    precision_recall_curve, auc, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helper: evaluation \n",
    "# =========================\n",
    "def evaluate_model(model_name, y_true, y_pred, y_pred_proba):\n",
    "    print(f\"\\n--- {model_name.upper()} EVALUATION ---\")\n",
    "    auc  = roc_auc_score(y_true, y_pred_proba)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
    "    ap   = average_precision_score(y_true, y_pred_proba)\n",
    "\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"PR AUC: {ap:.4f}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    total_0, total_1 = TN + FP, FN + TP\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "    print(f\"TN: {TN}, FP: {FP}, FN: {FN}, TP: {TP}\")\n",
    "    print(f\"Specificity: {TN/total_0:.4f}\")\n",
    "    print(f\"False Positive Rate: {FP/total_0:.4f}\")\n",
    "    print(f\"Sensitivity (Recall): {TP/total_1:.4f}\")\n",
    "    print(f\"False Negative Rate: {FN/total_1:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    return {\n",
    "        'model': model_name, 'auc': auc, 'pr_auc': ap, 'accuracy': acc,\n",
    "        'precision': prec, 'recall': rec, 'f1': f1, 'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Class weight & CV\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "########### 1. GRIDSEARCH MODEL ###########\n",
    "xgb_opt_base = XGBClassifier(\n",
    "    scale_pos_weight=pos_weight,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [400],          \n",
    "    \"max_depth\": [16, 20, 24],      \n",
    "    \"min_child_weight\": [1, 2],     \n",
    "    \"learning_rate\": [0.1],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.8],\n",
    "    \"reg_alpha\": [0.0, 0.1],        \n",
    "    \"reg_lambda\": [0.0, 0.1]        \n",
    "}\n",
    "\n",
    "grid_optimised = GridSearchCV(\n",
    "    estimator=xgb_opt_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=skf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_optimised.fit(X_train_selected, y_train)\n",
    "best_xgb = grid_optimised.best_estimator_\n",
    "\n",
    "y_pred_xgb_v1  = best_xgb.predict(X_test_selected)\n",
    "y_proba_xgb_v1 = best_xgb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "########### 2. FIXED-PARAM MODEL ###########\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=pos_weight,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred_xgb_v2  = xgb_model.predict(X_test_selected)\n",
    "y_proba_xgb_v2 = xgb_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "\n",
    "print(\"\\n========================\")\n",
    "print(\" GRIDSEARCH XGBOOST\")\n",
    "print(\"========================\")\n",
    "_ = evaluate_model(\n",
    "    \"XGBoost (GridSearch)\",\n",
    "    y_test,\n",
    "    y_pred_xgb_v1,\n",
    "    y_proba_xgb_v1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n========================\")\n",
    "print(\" FIXED XGBOOST (SPW + REG)\")\n",
    "print(\"========================\")\n",
    "_ = evaluate_model(\n",
    "    \"XGBoost (SPW + Reg)\",\n",
    "    y_test,\n",
    "    y_pred_xgb_v2,\n",
    "    y_proba_xgb_v2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a4c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. PLOTS: ROC, PR, METRIC BAR CHART\n",
    "# ============================================================\n",
    "\n",
    "# Baseline RF (class-weighted)\n",
    "rf_pred   = y_pred_cw\n",
    "rf_proba  = y_pred_proba_cw\n",
    "\n",
    "\n",
    "# RF (with FE)\n",
    "rf_fe_pred  = y_pred_eng\n",
    "rf_fe_proba = y_pred_proba_eng\n",
    "\n",
    "# Tuned XGBoost (with FE) - v1\n",
    "xgb_v1_pred  = y_pred_xgb_v1\n",
    "xgb_v1_proba = y_proba_xgb_v1\n",
    "\n",
    "# Tuned XGBoost (with FE) - v2\n",
    "xgb_v2_pred  = y_pred_xgb_v2\n",
    "xgb_v2_proba = y_proba_xgb_v2\n",
    "\n",
    "\n",
    "# --- ROC CURVES ---\n",
    "fpr_rf,    tpr_rf,    _ = roc_curve(y_test, rf_proba)\n",
    "fpr_rf_fe, tpr_rf_fe, _ = roc_curve(y_test, rf_fe_proba)\n",
    "fpr_xgb_v1, tpr_xgb_v1, _ = roc_curve(y_test, xgb_v1_proba)\n",
    "fpr_xgb_v2, tpr_xgb_v2, _ = roc_curve(y_test, xgb_v2_proba)\n",
    "\n",
    "auc_rf     = roc_auc_score(y_test, rf_proba)\n",
    "auc_rf_fe  = roc_auc_score(y_test, rf_fe_proba)\n",
    "auc_xgb_v1 = roc_auc_score(y_test, xgb_v1_proba)\n",
    "auc_xgb_v2 = roc_auc_score(y_test, xgb_v2_proba)\n",
    "\n",
    "# --- PRECISION–RECALL CURVES ---\n",
    "prec_rf,    recall_rf,    _ = precision_recall_curve(y_test, rf_proba)\n",
    "prec_rf_fe, recall_rf_fe, _ = precision_recall_curve(y_test, rf_fe_proba)\n",
    "prec_xgb_v1, recall_xgb_v1, _ = precision_recall_curve(y_test, xgb_v1_proba)\n",
    "prec_xgb_v2, recall_xgb_v2, _ = precision_recall_curve(y_test, xgb_v2_proba)\n",
    "\n",
    "ap_rf     = average_precision_score(y_test, rf_proba)\n",
    "ap_rf_fe  = average_precision_score(y_test, rf_fe_proba)\n",
    "ap_xgb_v1 = average_precision_score(y_test, xgb_v1_proba)\n",
    "ap_xgb_v2 = average_precision_score(y_test, xgb_v2_proba)\n",
    "\n",
    "# --- METRICS TABLE FOR BAR PLOT ---\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "\n",
    "rf_scores = [\n",
    "    accuracy_score(y_test, rf_pred),\n",
    "    precision_score(y_test, rf_pred, zero_division=0),\n",
    "    recall_score(y_test, rf_pred, zero_division=0),\n",
    "    f1_score(y_test, rf_pred, zero_division=0)\n",
    "]\n",
    "\n",
    "rf_fe_scores = [\n",
    "    accuracy_score(y_test, rf_fe_pred),\n",
    "    precision_score(y_test, rf_fe_pred, zero_division=0),\n",
    "    recall_score(y_test, rf_fe_pred, zero_division=0),\n",
    "    f1_score(y_test, rf_fe_pred, zero_division=0)\n",
    "]\n",
    "\n",
    "xgb_v1_scores = [\n",
    "    accuracy_score(y_test, xgb_v1_pred),\n",
    "    precision_score(y_test, xgb_v1_pred, zero_division=0),\n",
    "    recall_score(y_test, xgb_v1_pred, zero_division=0),\n",
    "    f1_score(y_test, xgb_v1_pred, zero_division=0)\n",
    "]\n",
    "\n",
    "xgb_v2_scores = [\n",
    "    accuracy_score(y_test, xgb_v2_pred),\n",
    "    precision_score(y_test, xgb_v2_pred, zero_division=0),\n",
    "    recall_score(y_test, xgb_v2_pred, zero_division=0),\n",
    "    f1_score(y_test, xgb_v2_pred, zero_division=0)\n",
    "]\n",
    "\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"Metric\": metrics,\n",
    "    \"RF (Baseline CW)\": rf_scores,\n",
    "    \"RF (FE)\": rf_fe_scores,\n",
    "    \"XGB Tuned (FE) v1\": xgb_v1_scores,\n",
    "    \"XGB Tuned (FE) v2\": xgb_v2_scores\n",
    "})\n",
    "\n",
    "# ============================================================\n",
    "# 6. VISUALISATIONS\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "# (1) ROC Curve\n",
    "axes[0].plot(fpr_rf,     tpr_rf,     label=f\"RF (Baseline CW)   AUC={auc_rf:.3f}\")\n",
    "axes[0].plot(fpr_rf_fe,  tpr_rf_fe,  label=f\"RF (FE)            AUC={auc_rf_fe:.3f}\")\n",
    "axes[0].plot(fpr_xgb_v1, tpr_xgb_v1, label=f\"XGB Tuned (FE) v1  AUC={auc_xgb_v1:.3f}\")\n",
    "axes[0].plot(fpr_xgb_v2, tpr_xgb_v2, label=f\"XGB Tuned (FE) v2  AUC={auc_xgb_v2:.3f}\")\n",
    "axes[0].plot([0, 1], [0, 1], linestyle=\"--\", color='gray')\n",
    "axes[0].set_title(\"ROC Curve\")\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# (2) Precision–Recall Curve\n",
    "axes[1].plot(recall_rf,     prec_rf,     label=f\"RF (Baseline CW)   AP={ap_rf:.3f}\")\n",
    "axes[1].plot(recall_rf_fe,  prec_rf_fe,  label=f\"RF (FE)            AP={ap_rf_fe:.3f}\")\n",
    "axes[1].plot(recall_xgb_v1, prec_xgb_v1, label=f\"XGB Tuned (FE) v1  AP={ap_xgb_v1:.3f}\")\n",
    "axes[1].plot(recall_xgb_v2, prec_xgb_v2, label=f\"XGB Tuned (FE) v2  AP={ap_xgb_v2:.3f}\")\n",
    "axes[1].axhline((y_test==1).mean(), ls='--', c='gray', lw=1, label='Baseline prevalence')\n",
    "axes[1].set_title(\"Precision–Recall Curve\")\n",
    "axes[1].set_xlabel(\"Recall\")\n",
    "axes[1].set_ylabel(\"Precision\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# (3) Bar Plot (Accuracy, Precision, Recall, F1)\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.2\n",
    "axes[2].bar(x - 1.5*width, df_metrics[\"RF (Baseline CW)\"], width, label=\"RF (Baseline CW)\")\n",
    "axes[2].bar(x - 0.5*width, df_metrics[\"RF (FE)\"],         width, label=\"RF (FE)\")\n",
    "axes[2].bar(x + 0.5*width, df_metrics[\"XGB Tuned (FE) v1\"], width, label=\"XGB Tuned (FE) v1\")\n",
    "axes[2].bar(x + 1.5*width, df_metrics[\"XGB Tuned (FE) v2\"], width, label=\"XGB Tuned (FE) v2\")\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(metrics)\n",
    "axes[2].set_ylabel(\"Score\")\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].set_title(\"Model Comparison\")\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"RF (CW) vs RF (FE) vs XGB Tuned v1 vs XGB Tuned v2\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227497db",
   "metadata": {},
   "source": [
    "In the context of credit default prediction, it is crucial to find the right balance between identifying true defaulters and minimizing false alarms. The precision-recall curve is a valuable tool for visualizing this trade-off, as it shows how precision (the proportion of correctly identified defaulters among all predicted defaulters) and recall (the proportion of actual defaulters correctly identified by the model) change as we adjust the classification threshold. In practical terms, if our main concern is to avoid lending to customers who are likely to default, we may prioritize a higher recall, accepting a greater number of false positives to ensure we capture as many defaulters as possible. Conversely, if we want to avoid mistakenly classifying reliable customers as risky, we might set a higher threshold to achieve higher precision, even if it means some defaulters go undetected. By analyzing the precision-recall curve, we can select a threshold that aligns with our institution’s risk appetite and business objectives, ensuring our credit decision process is both responsible and aligned with our strategic goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392c03e",
   "metadata": {},
   "source": [
    "## 4. Learning curve \n",
    "\n",
    "Plot that shows the relationship between the size of training dataset and the model's performance on both training and validation/test set. It tells us how the model’s performance improves (or stagnates) as it sees more data.\n",
    "\n",
    "1. XGBoost can be prone to overfitting if not tuned well, thus, we displayed the learning curve to see if the current hyperparameter settings is fitting the data well.\n",
    "- High training score but low validation score suggests model is overfitting.\n",
    "- Low training and validation scores suggest model is underfitting.\n",
    "\n",
    "\n",
    "2. See if adding more data would help:\n",
    "- If validation score is still improving with more data, more samples might help.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, StratifiedKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Unfitted model instances (corresponding exactly to the 4 models)\n",
    "# -------------------------------------------------\n",
    "\n",
    "# 1) Baseline RF (class-weighted)\n",
    "rf_lc = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) RF (with FE)\n",
    "rf_fe_lc = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    class_weight=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) Tuned XGBoost v1 (GridSearch best model)  ← MUST USE best_xgb.get_params()\n",
    "xgb_v1_lc = XGBClassifier(\n",
    "    **best_xgb.get_params()\n",
    ")\n",
    "\n",
    "# 4) Tuned XGBoost v2 (fixed SPW + Reg) ← must match EXACT fixed v2 params\n",
    "xgb_v2_lc = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Stratified CV \n",
    "# -------------------------------------------------\n",
    "skf5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Helper function for learning curves\n",
    "# -------------------------------------------------\n",
    "def get_curve(estimator, X, y, cv):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator=estimator,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_mean = val_scores.mean(axis=1)\n",
    "    val_std = val_scores.std(axis=1)\n",
    "    return train_sizes, val_mean, val_std\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Get learning curves for each model\n",
    "# -------------------------------------------------\n",
    "\n",
    "# RF baseline uses raw features\n",
    "sizes_rf, val_rf, std_rf = get_curve(rf_lc, X_train, y_train, skf5)\n",
    "\n",
    "# RF FE uses engineered features\n",
    "sizes_rf_fe, val_rf_fe, std_rf_fe = get_curve(rf_fe_lc, X_train_selected, y_train, skf5)\n",
    "\n",
    "# XGB v1 uses engineered features\n",
    "sizes_v1, val_v1, std_v1 = get_curve(xgb_v1_lc, X_train_selected, y_train, skf5)\n",
    "\n",
    "# XGB v2 uses engineered features\n",
    "sizes_v2, val_v2, std_v2 = get_curve(xgb_v2_lc, X_train_selected, y_train, skf5)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Plot learning curves\n",
    "# -------------------------------------------------\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Uncertainty bands\n",
    "plt.fill_between(sizes_rf,    val_rf - std_rf,    val_rf + std_rf,    alpha=0.1)\n",
    "plt.fill_between(sizes_rf_fe, val_rf_fe - std_rf_fe, val_rf_fe + std_rf_fe, alpha=0.1)\n",
    "plt.fill_between(sizes_v1,    val_v1 - std_v1,    val_v1 + std_v1,    alpha=0.1)\n",
    "plt.fill_between(sizes_v2,    val_v2 - std_v2,    val_v2 + std_v2,    alpha=0.1)\n",
    "\n",
    "# Mean curves\n",
    "plt.plot(sizes_rf,    val_rf,    'o-', label=\"RF (class-weighted)\")\n",
    "plt.plot(sizes_rf_fe, val_rf_fe, 's--', label=\"RF (FE)\")\n",
    "plt.plot(sizes_v1,    val_v1,    'd-.', label=\"XGB v1 (Tuned GridSearch)\")\n",
    "plt.plot(sizes_v2,    val_v2,    'x-', label=\"XGB v2 (Fixed SPW + Reg)\")\n",
    "\n",
    "plt.xlabel(\"Number of Training Samples\")\n",
    "plt.ylabel(\"Validation ROC AUC (5-fold)\")\n",
    "plt.title(\"Learning Curves: 4 Model Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs3244",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
